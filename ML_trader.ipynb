{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Create a machine learning model to trade cryptocurrency</h1>\n\n<p>In this jupyter notebook, I want to create a bot that can make money from the cryptocurrency market</p>\n<p>Common methods for forecasting financial markets are usually time series methods such as ARIMA, etc., but I want to solve this problem with a new approach.\nIn this jupyter notebook, I use classification models to solve this challenge.</p>","metadata":{}},{"cell_type":"markdown","source":"<h3>>>> Importing necessary modules </h3>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport ccxt\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom xgboost import plot_importance\nfrom sklearn.model_selection import cross_val_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>>>> Collect data from binance API</h3>\n\n<p>We used the ccxt module to get the data.</p>\n<p>For more information about this powerful module, you can use the following link. <a href=\"https://github.com/ccxt/ccxt\"> CCXT â€“ CryptoCurrency eXchange Trading Library\n</a></p>\n\n\n<p>We collect all daily ETH USDT data from the Binance broker.</p>\n<p>This information consists of 5 columns which are date, open, high, low, close and volume.</p>\n<ul>\n    <li>date: The time of opening the candle</li>\n    <li>open: The first price traded</li>\n    <li>high: The highest price traded</li>\n    <li>low: The lowest price traded</li>\n    <li>close: Last traded price</li>\n    <li>volume: traded volume</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"# \"\"\" import all ETHUSDT OHLC data from Binance \"\"\"\ncoin='ETH/USDT'\ntimeframe='1d'\nexchange=ccxt.binance()\nstart_date=0\n# start_date = int(datetime.datetime(2017, 1, 1, 1, 1).timestamp() * 1000)\n\ndata=pd.DataFrame(columns=['date', 'open', 'high', 'low', 'close', 'volume'])\n\nwhile True:\n    response=exchange.fetch_ohlcv(coin, timeframe, since=start_date, limit=1000)\n    df=pd.DataFrame(response, columns=['date', 'open', 'high', 'low', 'close', 'volume'])\n    updateData=pd.merge(data, df, how='outer')\n    if len(data)!=len(updateData):\n        data=updateData.copy()\n        start_date=data['date'].iloc[-1]\n    else:\n        break\n    \ndata.drop_duplicates(inplace=True,subset=['date'])\ndata.date=pd.to_datetime(data['date'], unit='ms', utc=True, yearfirst=True)\ndata.drop(data.tail(1).index,inplace=True) # because the last row is not close\ndata.to_csv('data.csv')\nprint(data.head(5))\nprint(data.tail(5))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>>>> Create independent variable</h3>\n\n<h4>DrawDown</h4>\n<p>To use the machine learning model, we need more predictive variables.\nOne of the variables we can use is drawdown.</p>\n<p>A drawdown is a peak-to-trough decline during a specific period for an investment, trading account, or fund. A drawdown is usually quoted as the percentage between the peak and the subsequent trough. If a trading account has 10,000 dollar in it, and the funds drop to 9,000 dollar before moving back above 10,000 dollar, then the trading account witnessed a 10 drawdown.</p>\n","metadata":{}},{"cell_type":"code","source":"# Calculate drawdown\nHighestHigh = [data['high'].iloc[0]]\nfor i in range(1,len(data)):\n    if data['high'].iloc[i] >= HighestHigh[-1]:\n        HighestHigh.append(data['high'].iloc[i])\n    else:\n        HighestHigh.append(HighestHigh[-1])\n        \ndata['HighestHigh'] = HighestHigh\ndata['DrawDown'] = data.apply(lambda row: 0 if row['high']==row['HighestHigh'] else (row['low']-row['HighestHigh'])*100/row['HighestHigh'], axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4>Maximum drawdown(MDD)</h4>\n<p>Maximum drawdown is a specific measure of drawdown that looks for the greatest movement from a high point to a low point, before a new peak is achieved.<p>","metadata":{}},{"cell_type":"code","source":"# Maximum Drawdown (MDD) \nprint(\"Maximum Drawdown (MDD): {0} %\".format(data.loc[data['DrawDown'] == min(data['DrawDown']) ,\"DrawDown\"].values[0].round(2)))  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot drawdown\nplt.figure(figsize=(15,7))\nplt.plot(data['date'], data['DrawDown'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add important variables\n\nfor i in range(1,51):\n    data['pctchange{0}'.format(i)]=data['close'].pct_change(i)\n\nfor i in range(1,51):\n    data['pctchange1_{0}'.format(i)] = data['pctchange1'].shift(i)\n    data['DrawDown{0}'.format(i)] = data['DrawDown'].shift(i)\n\ndata['year']=data['date'].dt.year\ndata['month']=data['date'].dt.month\ndata['day']=data['date'].dt.day\ndata['dayofyear']=data['date'].dt.dayofyear\n\ndata.dropna(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>>>> Defining dependent variable</h3>\n<p>Here we define our dependent variable as follows:\nIf the next candle has a price increase of more than 1%, we will enter the buying position.\nWe can use any amount more from the exchange commission because of that way we make a profit.</p>\n<p>with this trick, we can now use classification models :)</p>","metadata":{}},{"cell_type":"code","source":"data['target']=data['pctchange1'].apply(lambda x : 1 if x>0.01 else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>>>> Split the dataset into a training dataset and a test dataset</h3>\n<p>The train-test split procedure is used to estimate the performance of machine learning algorithms when they are used to make predictions on data not used to train the model.</p>","metadata":{}},{"cell_type":"code","source":"# we subset our data frame to \nX_train, X_test, y_train, y_test = train_test_split(data[data.columns.difference(['date','pctchange1','target'])], data['target'], test_size=0.33, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>>>> Create XGboost model</h3>","metadata":{}},{"cell_type":"code","source":"xg_reg = xgb.XGBClassifier(num_class=1,\n                            learning_rate=0.1,\n                            max_depth=10,\n                            scale_pos_weight=1.5,\n                            eval_metric='mlogloss',\n                            use_label_encoder=False)\nxg_reg.fit( X_train, y_train )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>>>> Top 10 most important features</h3>","metadata":{}},{"cell_type":"code","source":"ax= plot_importance( xg_reg , height=0.9, max_num_features=15)\nfig = ax.figure\nfig.set_size_inches(15, 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p><i>We found that the drawdown variable did not have much effect on predicting our dependent variable and we could remove it from the model training process in the future.</i><p>","metadata":{}},{"cell_type":"markdown","source":"<h3>>>> K-fold Cross Validation</h3>\n<p>Cross-validation is a statistical method used to estimate the skill of machine learning models.</p>\n<p>For more information about k-fold cross validation, you can use the following link. <a href=\"https://machinelearningmastery.com/k-fold-cross-validation/\">K-fold Cross Validation</a></p>\n\n\n\n<img alt=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" class=\"align-center\" src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" style=\"width: 500px; height: 300px;\">\n","metadata":{}},{"cell_type":"code","source":"accuracies = cross_val_score(estimator=xg_reg, X=X_train, y=y_train, cv=10, scoring='accuracy')\nprint(\"Accuracy Mean: {0}, Accuracy standard deviation: {1}\".format(accuracies.mean(),accuracies.std())) \nrecall = cross_val_score(estimator=xg_reg, X=X_train, y=y_train, cv=10, scoring='recall')\nprint(\"recall Mean: {0}, recall standard deviation: {1}\".format(recall.mean(),recall.std()))\nprecision=cross_val_score(estimator=xg_reg, X=X_train, y=y_train, cv=10, scoring='precision')\nprint(\"precision Mean: {0}, precision standard deviation: {1}\".format(precision.mean(),precision.std()))\nF_score =cross_val_score(estimator=xg_reg, X=X_train, y=y_train, cv=10, scoring='f1')\nprint(\"F_score Mean: {0}, F_score standard deviation: {1}\".format(F_score.mean(),F_score.std()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>>>> Predict data</h3>","metadata":{}},{"cell_type":"code","source":"y_pred = xg_reg.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>>>> Confusion Matrix</h3>\n<p>A confusion matrix is used to check the performance of a classification model on a set of test data for which the true values are known. Most performance measures such as precision, recall are calculated from the confusion matrix.\n</p>\n<p>For more information about confusion matrix, you can use the following link. <a href=\"https://keytodatascience.com/confusion-matrix/\">confusion-matrix</a></p>\n\n<img src=\"https://keytodatascience.com/wp-content/uploads/2019/09/binary-classification.jpg\" alt=\"https://keytodatascience.com/wp-content/uploads/2019/09/binary-classification.jpg\" width=\"378\" height=\"263\">\n<img width=\"378\" height=\"263\" src=\"https://keytodatascience.com/wp-content/uploads/2019/09/values-3.jpg\" alt=\"https://keytodatascience.com/wp-content/uploads/2019/09/values-3.jpg\">","metadata":{}},{"cell_type":"code","source":"TN=0 \nTP=0\nFP=0\nFN=0\nfor i in range(len(y_pred)):\n    if y_pred[i]==1 and y_test.values[i]==1:\n        TP+=1\n    elif y_pred[i]==0 and y_test.values[i]==0:\n        TN+=1\n    elif y_pred[i]==1 and y_test.values[i]==0 :\n        FP+=1\n    else:\n        FN+=1\n\nAccuracy=(TP+TN)/(TP+TN+FP+FN)\nRecall= TP/(TP+FN)\nPrecision= TP/(TP+FP)\nF_score= (2*Recall*Precision)/(Recall+Precision)\n\nprint(\"Accuracy : {0}\".format(Accuracy))\nprint(\"Recall : {0}\".format(Recall))\nprint(\"Precision : {0}\".format(Precision))\nprint(\"F_score : {0}\".format(F_score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}